{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4368f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#general purpose packages\n",
    "\n",
    "# nlp\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk,string\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
    "from nltk.stem import PorterStemmer     # parsing/stemmer\n",
    "from nltk.tag import pos_tag            # parts-of-speech tagging\n",
    "from nltk.corpus import wordnet         # sentiment scores\n",
    "from nltk.stem import WordNetLemmatizer # stem and context\n",
    "from nltk.corpus import stopwords       # stopwords\n",
    "from nltk.util import ngrams            # ngram iterator\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# import word2vec|\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# import sklearn\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68433a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>3-Nov-15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53761</th>\n",
       "      <td>159999</td>\n",
       "      <td>Tamoxifen</td>\n",
       "      <td>Breast Cancer, Prevention</td>\n",
       "      <td>\"I have taken Tamoxifen for 5 years. Side effe...</td>\n",
       "      <td>10</td>\n",
       "      <td>13-Sep-14</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53762</th>\n",
       "      <td>140714</td>\n",
       "      <td>Escitalopram</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"I&amp;#039;ve been taking Lexapro (escitaploprgra...</td>\n",
       "      <td>9</td>\n",
       "      <td>8-Oct-16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53763</th>\n",
       "      <td>130945</td>\n",
       "      <td>Levonorgestrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I&amp;#039;m married, 34 years old and I have no ...</td>\n",
       "      <td>8</td>\n",
       "      <td>15-Nov-10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53764</th>\n",
       "      <td>47656</td>\n",
       "      <td>Tapentadol</td>\n",
       "      <td>Pain</td>\n",
       "      <td>\"I was prescribed Nucynta for severe neck/shou...</td>\n",
       "      <td>1</td>\n",
       "      <td>28-Nov-11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53765</th>\n",
       "      <td>113712</td>\n",
       "      <td>Arthrotec</td>\n",
       "      <td>Sciatica</td>\n",
       "      <td>\"It works!!!\"</td>\n",
       "      <td>9</td>\n",
       "      <td>13-Sep-09</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215063 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uniqueID                  drugName                     condition  \\\n",
       "0        206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1         95260                Guanfacine                          ADHD   \n",
       "2         92703                    Lybrel                 Birth Control   \n",
       "3        138000                Ortho Evra                 Birth Control   \n",
       "4         35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "...         ...                       ...                           ...   \n",
       "53761    159999                 Tamoxifen     Breast Cancer, Prevention   \n",
       "53762    140714              Escitalopram                       Anxiety   \n",
       "53763    130945            Levonorgestrel                 Birth Control   \n",
       "53764     47656                Tapentadol                          Pain   \n",
       "53765    113712                 Arthrotec                      Sciatica   \n",
       "\n",
       "                                                  review  rating       date  \\\n",
       "0      \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1      \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2      \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "3      \"This is my first time using any form of birth...       8   3-Nov-15   \n",
       "4      \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
       "...                                                  ...     ...        ...   \n",
       "53761  \"I have taken Tamoxifen for 5 years. Side effe...      10  13-Sep-14   \n",
       "53762  \"I&#039;ve been taking Lexapro (escitaploprgra...       9   8-Oct-16   \n",
       "53763  \"I&#039;m married, 34 years old and I have no ...       8  15-Nov-10   \n",
       "53764  \"I was prescribed Nucynta for severe neck/shou...       1  28-Nov-11   \n",
       "53765                                      \"It works!!!\"       9  13-Sep-09   \n",
       "\n",
       "       usefulCount  \n",
       "0               27  \n",
       "1              192  \n",
       "2               17  \n",
       "3               10  \n",
       "4               37  \n",
       "...            ...  \n",
       "53761           43  \n",
       "53762           11  \n",
       "53763            7  \n",
       "53764           20  \n",
       "53765           46  \n",
       "\n",
       "[215063 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "train_data = pd.read_csv('C:/Users/whtwht97/Desktop/Document/UChicago/Q2 - Health Analytics/final proj/drugsComTrain_raw.csv')\n",
    "test_data = pd.read_csv('C:/Users/whtwht97/Desktop/Document/UChicago/Q2 - Health Analytics/final proj/drugsComTest_raw.csv')\n",
    "df = pd.concat([train_data,test_data])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "644bd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=[\"review\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7074ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sentiment labels\n",
    "df[\"sentiment\"] = np.where(df[\"rating\"] > 7, 1, np.where(df[\"rating\"] < 4, -1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e1da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def review_cleaner(review, lemmatize=True, stem=False):\n",
    "    '''\n",
    "        Clean and preprocess a review.\n",
    "            1. Remove HTML tags\n",
    "            2. Extract emoticons\n",
    "            3. Use regex to remove all special characters (only keep letters)\n",
    "            4. Make strings to lower case and tokenize / word split reviews\n",
    "            5. Remove English stopwords\n",
    "            6. Lemmatize\n",
    "            7. Rejoin to one string\n",
    "        \n",
    "        @review (type:str) is an unprocessed review string\n",
    "        @return (type:str) is a 6-step preprocessed review string\n",
    "    '''\n",
    "    if lemmatize == True and stem == True:\n",
    "        raise RuntimeError(\"May not pass both lemmatize and stem flags\")\n",
    "\n",
    "    #1. Remove HTML tags\n",
    "    review = BeautifulSoup(review, \"lxml\").text\n",
    "\n",
    "    #2. Use regex to find emoticons\n",
    "    pattern2 ='(?::|;|=)(?:-)?(?:\\)|\\(|D|P)'\n",
    "    emoticons = re.findall(pattern2,review)\n",
    "\n",
    "    #3. Remove punctuation\n",
    "    pattern3 = r\"[^\\w+ \\d+]\"\n",
    "    review = re.sub(pattern3, \"\",review)\n",
    "\n",
    "    #4. Tokenize into words (all lower case)\n",
    "    review = review.lower()\n",
    "\n",
    "    #5. Remove stopwords, Lemmatize, Stem\n",
    "    word_tokens = word_tokenize(review)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in eng_stopwords]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "         if w not in eng_stopwords:               \n",
    "                w = wnl.lemmatize(w)              \n",
    "                filtered_sentence.append(w)\n",
    "                  \n",
    "    #6. Join the review to one sentence\n",
    "    filtered_sentence = \" \".join(filtered_sentence+emoticons)        \n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071da75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].apply(review_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d038db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for text in df.review:\n",
    "        temp = len(text.split())\n",
    "        result.append(temp)\n",
    "        \n",
    "df[\"text_len\"] = result\n",
    "df[\"text_len\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7ae683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"text_len\"]<=150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a17eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df[df.uniqueID.isin(test_data[\"uniqueID\"].values)].reset_index(drop=True)\n",
    "train_data = df[df.uniqueID.isin(train_data[\"uniqueID\"].values)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de81baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign x and y\n",
    "train_x = train_data[\"review\"]\n",
    "test_x = test_data[\"review\"]\n",
    "train_y = train_data[\"sentiment\"]\n",
    "test_y = test_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad19309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer fit and transform\n",
    "clf = CountVectorizer(ngram_range=(1,4),max_df=0.9)\n",
    "X_train_cv =  clf.fit_transform(train_x)\n",
    "X_test_cv = clf.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d360857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = X_train_cv.astype(\"float64\")\n",
    "train_y = train_y.astype(\"float64\")\n",
    "X_test_cv = X_test_cv.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70a30949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIGHTGBM\n",
    "gbm_clf = lightgbm.LGBMClassifier(learning_rate=0.2,num_leaves=40,max_depth=20)\n",
    "gbm_clf.fit(X_train_cv, train_y)\n",
    "gbm_pred = gbm_clf.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94d04b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tClassification Report for LightGBM:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.68      0.63      0.65      3539\n",
      "     Neutral       0.44      0.18      0.25      2819\n",
      "    Positive       0.77      0.92      0.84      9780\n",
      "\n",
      "    accuracy                           0.73     16138\n",
      "   macro avg       0.63      0.58      0.58     16138\n",
      "weighted avg       0.69      0.73      0.69     16138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\tClassification Report for LightGBM:\\n\\n',classification_report(test_y,gbm_pred, target_names=['Negative', 'Neutral', 'Positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
